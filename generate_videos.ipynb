{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import prettytensor as pt\n",
    "from generator import BEGAN_Generator as generator\n",
    "from discriminator import BEGAN_Discriminator as discriminator\n",
    "from utils.misc import loadData, dataIterator\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from utils.misc import plot_gens\n",
    "import time\n",
    "from config import checkpoint_path, checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BEGAN:\n",
    "    loss_tracker= {'generator': [],\n",
    "                  'discriminator' : [],\n",
    "                  'convergence_measure': []}\n",
    "    \n",
    "    def loss(D_real_in, D_real_out, D_gen_in, D_gen_out, k_t, gamma=0.75):\n",
    "        \n",
    "        def pixel_autoencoder_loss(out, inp):\n",
    "            \n",
    "            eta = 1\n",
    "            difff = tf.abs(out - inp)\n",
    "            if eta == 1:\n",
    "                return tf.reduce_sum(diff)\n",
    "            else:\n",
    "                return tf.reduce_sum(tf.pow(diff, eta))\n",
    "            \n",
    "            \n",
    "        \n",
    "        mu_real = pixel_autoencoder_loss(D_real_out, D_real_in)\n",
    "        mu_gen = pixel_autoencoder_loss(D_gen_out, D_gen_in)\n",
    "        D_loss = mu_real - (k_t * mu_gen)\n",
    "        G_loss = mu_gen\n",
    "        \n",
    "        lam = 0.001\n",
    "        k_tp = k_t + lam * (gamma * mu_real - mu_gen)\n",
    "        convergence_measure = mu_real + np.abs(gamma * mu_real - mu_gen)\n",
    "        \n",
    "        return D_loss, G_loss, k_tp, convergence_measure\n",
    "    \n",
    "    \n",
    "    def run(x, batch_size, hidden_size):\n",
    "        Z = tf.random_noraml((batch_size, hidden_size), 0, 1)\n",
    "        \n",
    "        with pt.defaults_scope(learned_moments_update_rate = 0.003,\n",
    "                               variance_epsilon = 0.001):\n",
    "            \n",
    "            x_tilde = generator(Z, batch_size = batch_size)\n",
    "            x_tilde_d = discriminator(x_tilde, batch_size = batch_size, \n",
    "                                     hidden_size = hidden_size)\n",
    "            \n",
    "            x_d = discriminator(x, reuse_scope = True, batch_size = batch_size,\n",
    "                               hidden_size = hidden_size)\n",
    "            \n",
    "            return x_tilde, x_tilde_d, x_d\n",
    "        \n",
    "        scopes = ['generator', 'discriminator']        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def began_train(images, start_epoch=0, add_epochs=None, batch_size=16,\n",
    "                hidden_size=2048, dim=(64, 64, 3), gpu_id='/gpu:0',\n",
    "                demo=False, get=False, start_learn_rate=1e-5, decay_every=50,\n",
    "                save_every=1, batch_norm=True, gamma=0.75):\n",
    "\n",
    "    num_epochs = start_epoch + add_epochs\n",
    "    loss_tracker = BEGAN.loss_tracker\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        global_step = tf.get_variable('global_step', [],\n",
    "                                      initializer=tf.constant_initializer(0),\n",
    "                                      trainable=False)\n",
    "\n",
    "        with tf.device(gpu_id):\n",
    "            learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "            opt = tf.train.AdamOptimizer(learning_rate, epsilon=1.0)\n",
    "\n",
    "            next_batch = tf.placeholder(tf.float32,\n",
    "                                        [batch_size, np.product(dim)])\n",
    "\n",
    "            x_tilde, x_tilde_d, x_d = BEGAN.run(next_batch, batch_size,\n",
    "                                                hidden_size)\n",
    "\n",
    "            k_t = tf.placeholder(tf.float32, shape=[])\n",
    "            D_loss, G_loss, k_tp, convergence_measure = \\\n",
    "                BEGAN.loss(next_batch, x_d, x_tilde, x_tilde_d, k_t=k_t)\n",
    "\n",
    "            params = tf.trainable_variables()\n",
    "            tr_vars = {}\n",
    "            for s in BEGAN.scopes:\n",
    "                tr_vars[s] = [i for i in params if s in i.name]\n",
    "\n",
    "            G_grad = opt.compute_gradients(G_loss,\n",
    "                                           var_list=tr_vars['generator'])\n",
    "\n",
    "            D_grad = opt.compute_gradients(D_loss,\n",
    "                                           var_list=tr_vars['discriminator'])\n",
    "\n",
    "            G_train = opt.apply_gradients(G_grad, global_step=global_step)\n",
    "            D_train = opt.apply_gradients(D_grad, global_step=global_step)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        sess = tf.Session(graph=graph,\n",
    "                          config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                log_device_placement=True))\n",
    "        sess.run(init)\n",
    "    if start_epoch > 0:\n",
    "        path = '{}/{}_{}.tfmod'.format(checkpoint_path,\n",
    "                                       checkpoint_prefix,\n",
    "                                       str(start_epoch-1).zfill(4))\n",
    "        tf.train.Saver.restore(saver, sess, path)\n",
    "\n",
    "    k_t_ = 0  # We initialise with k_t = 0 as in the paper.\n",
    "    num_batches_per_epoch = int(len(images) / batch_size)\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print('Epoch {} / {}'.format(epoch + 1, num_epochs + 1))\n",
    "        for i in tqdm.tqdm(range(num_batches_per_epoch)):\n",
    "            iter_ = dataIterator([images], batch_size)\n",
    "\n",
    "            learning_rate_ = start_learn_rate * pow(0.5, epoch // decay_every)\n",
    "            next_batch_ = next(iter_)\n",
    "\n",
    "            _, _, D_loss_, G_loss_, k_t_ = \\\n",
    "                sess.run([G_train, D_train, D_loss, G_loss, k_tp],\n",
    "                         {learning_rate: learning_rate_,\n",
    "                          next_batch: next_batch_, k_t: min(max(k_t_, 0), 1)})\n",
    "\n",
    "            loss_tracker['generator'].append(G_loss_)\n",
    "            loss_tracker['discriminator'].append(D_loss_)\n",
    "            loss_tracker['convergence_measure'].append(0)\n",
    "\n",
    "        if epoch % save_every == 0:\n",
    "            path = '{}/{}_{}.tfmod'.format(checkpoint_path,\n",
    "                                           checkpoint_prefix,\n",
    "                                           str(epoch).zfill(4))\n",
    "            saver.save(sess, path)\n",
    "    if demo:\n",
    "        batch = dataIterator([images], batch_size).__next__()\n",
    "        ims = sess.run(x_tilde)\n",
    "        plot_gens((ims, batch),\n",
    "                  ('Generated 64x64 samples.', 'Random training images.'),\n",
    "                  loss_tracker)\n",
    "        if get:\n",
    "            return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train(start_epoch, train, add_epochs, max_images=50000, **k):\n",
    "    SE = start_epoch\n",
    "    while start_epoch <= SE + add_epochs:\n",
    "        i = 0\n",
    "        while True:\n",
    "            images = loadData(size=max_images, offset=i)\n",
    "            if train is False:\n",
    "                return began_train(images, start_epoch=start_epoch,\n",
    "                                   add_epochs=0, demo=True, get=True, **k)\n",
    "            began_train(images, start_epoch=start_epoch, add_epochs=1,\n",
    "                        **k)\n",
    "            start_epoch += 1\n",
    "            i += 1\n",
    "            if len(images) < max_images:\n",
    "                break\n",
    "            del images\n",
    "            time.sleep(30)  # Let my GPU cool down\n",
    "        print('full cycle finished. Good time to stop.')\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    im = _train(start_epoch = 0, add_epochs = 100, save_every = 5, train = True )\n",
    "    if not args.train:\n",
    "        import matplotlib.pyplot as plt\n",
    "        for n in range(8):\n",
    "            im_to_save = im[n].reshape([64, 64, 3])\n",
    "            plt.imsave(args.outdir+'/out_{}.jpg'.format(n),\n",
    "                       im_to_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
